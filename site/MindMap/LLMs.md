# Llama-2
* A more efficient training process
- A better ability to generalize to new tasks
- Llama-v2 outperforms previous LLMs 
	- on a variety of benchmark tasks, 
	- question answering, summarization, and translation.
- Llama-v2 is more efficient to train than previous LLMs, requiring less compute and time.
- Llama-v2 is able to generalize to new tasks better than previous LLMs.
* Llama-v2 is available on Microsoft Azure, AWS, Hugging Face 
* Llama-v2 is open source, with a license that authorizes commercial use
* Llama-v2 is a significant advancement over previous LLMs.
* Pretrained and fine-tuned models are available with 7B, 13B, and 70B parameters.
* Llama-2 website: [https://ai.meta.com/llama/](https://ai.meta.com/llama/)  
* Llama-2 paper: [https://lnkd.in/djeTCvfn](https://lnkd.in/djeTCvfn)  
* Fine-tune Llama-2 with few lines of code
	* Fine-tuning script: [https://lnkd.in/eceMyUBW](https://lnkd.in/eceMyUBW)  
	* Link to blogpost: [https://lnkd.in/eWydP72S](https://lnkd.in/eWydP72S)
